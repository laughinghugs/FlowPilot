{"plan_id": "018a981f-b8c8-49d9-9bd6-6ccd8095e26d", "created_at": "2025-12-16T09:52:47+00:00", "user_message": "We want to apply LLMs with retrieval over equipment manuals, process docs, and historical issue reports so engineers can ask questions about manufacturing problems and past resolutions.", "system_prompt": null, "steps": [{"tool": "CompositeRetriever", "rationale": "Unify retrieval across manuals, process docs, and historical issue reports using multiple in-memory keyword indices with tailored field boosts and query expansion (synonyms/acronyms).", "metadata": {"sources": ["manuals", "process_docs", "issue_reports"], "per_source_top_k": {"manuals": 20, "process_docs": 15, "issue_reports": 25}, "query_preprocessing": {"lowercase": true, "remove_punctuation": true, "lemmatize": true}, "query_expansion": {"synonyms": true, "acronyms": true, "spelling_correction": true}, "filters": {"equipment_model_from_query": true, "language_from_query": true}, "field_boosts": {"manuals": {"title": 2.0, "section": 1.3, "content": 1.0}, "process_docs": {"title": 1.6, "procedure": 1.3, "content": 1.0}, "issue_reports": {"title": 1.5, "symptom": 2.0, "resolution": 2.0, "content": 1.0}}, "return_fields": ["doc_id", "source", "title", "section", "content", "equipment_models", "published_at"], "max_candidates": 60}}, {"tool": "HeuristicReranker", "rationale": "Reorder retrieved passages by combined relevance, equipment/entity match, recency, and source priority (favor past resolutions for troubleshooting).", "metadata": {"top_k": 12, "weights": {"text_relevance": 0.5, "equipment_match": 0.2, "recency": 0.15, "source_priority": 0.15}, "source_priority": {"issue_reports": 3, "process_docs": 2, "manuals": 1}, "recency_halflife_days": 365, "deduplicate_by": "doc_id", "diversity_penalty": 0.1}}, {"tool": "LLMGenerator", "rationale": "Generate grounded answers that synthesize retrieved context into troubleshooting guidance and cite sources; low temperature to reduce hallucinations.", "metadata": {"model": "default", "temperature": 0.2, "max_tokens": 900, "prompt_template": "You are an expert manufacturing support assistant. Use ONLY the provided context to answer. Cite sources as [doc_id:section]. If evidence is insufficient, ask for the missing details before proposing actions. Include: summary, likely causes, step-by-step checks, known past fixes with links, and safety/warranty notes. Do not invent part numbers or procedures.", "grounding_mode": "strict", "refuse_if_insufficient_evidence": true, "include_citations": true}}, {"tool": "TemplateLLMGenerator", "rationale": "Enforce a consistent, deterministic output schema for engineering consumption and downstream logging/analytics.", "metadata": {"template_name": "troubleshooting_answer_v1", "schema": {"summary": "string", "suspected_causes": ["string"], "recommended_checks": [{"step": "string", "expected_result": "string"}], "past_cases": [{"issue_id": "string", "symptom": "string", "resolution": "string"}], "citations": [{"doc_id": "string", "section": "string"}], "missing_info": ["string"], "safety_notes": ["string"], "confidence": "number"}, "enforce_citations": true}}, {"tool": "InMemoryRetriever", "rationale": "Provide a targeted fallback search (e.g., by exact equipment model/part number) when the composite strategy yields sparse results.", "metadata": {"top_k": 8, "match_mode": "exact_keyword", "boost_fields": ["equipment_models", "part_numbers", "title"]}}, {"tool": "RagasEvaluator", "rationale": "Quantitatively evaluate retrieval and generation quality on a curated set of manufacturing troubleshooting queries.", "metadata": {"metrics": ["answer_relevancy", "faithfulness", "context_precision", "context_recall"], "thresholds": {"answer_relevancy": 0.7, "faithfulness": 0.9, "context_precision": 0.6, "context_recall": 0.6}, "dataset_size": 100, "report_format": "json", "stratification": {"by_equipment_model": true, "by_issue_category": true}, "negative_controls": 10}}]}
